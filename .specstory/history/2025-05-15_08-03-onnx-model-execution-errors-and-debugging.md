<!-- Generated by SpecStory -->

# ONNX Model Execution Errors and Debugging (2025-05-15 16:03:44)

_**User**_

[logServer connected.][/iflytek/data1/zhinengti/server/skynet/log/turing-embedding-v10@turing-planet/turing-embedding-v10@turing-planet_console.log]
2. End must be called once.
3. End must be called once.
4. OnnxModelProcess.hpp:115 onnx core run error2025-05-15 18:18:12.993033955 [E:onnxruntime:, sequential_executor.cc:761 Execute] Non-zero status code returned while running Gather node. Name:'Gather_342' Status Message: CUDA error cudaErrorNoKernelImageForDevice:no kernel image is available for execution on the device
5. Begin must be called once.
6. End must be called once.
7. End must be called once.
8. OnnxModelProcess.hpp:115 onnx core run error05-15 18:18:12.993 ERROR [http-nio-9987-exec-2] c.i.t.e.pandora.EmbeddingHandler [103]: doc-qa process error:TALKER.DOCQA.wrapperExec failed! engine code:15005
9. com.iflytek.turing.docqa.exceptions.DocQaEngineException: TALKER.DOCQA.wrapperExec failed! engine code:15005
10. at com.iflytek.turing.docqa.exceptions.DocQaEngineErrors.checkResult(DocQaEngineErrors.java:22)
11. at com.iflytek.turing.docqa.utils.AIEngineApiExe.exeLibApi(AIEngineApiExe.java:28)
12. at com.iflytek.turing.docqa.DocQaWorker.embedding(DocQaWorker.java:30)
13. at com.iflytek.turing.embedding.pandora.EmbeddingHandler.process(EmbeddingHandler.java:95)
14. at skynet.boot.pandora.service.support.func.FuncHandlerWrapper.run(FuncHandlerWrapper.java:46)
15. at skynet.boot.pandora.service.support.func.FuncHandlerManager.run(FuncHandlerManager.java:93)
16. at skynet.boot.pandora.FuncServiceEndpoint.process(FuncServiceEndpoint.java:57)
17. at skynet.boot.pandora.FuncServiceEndpoint$$FastClassBySpringCGLIB$$7ecb2765.invoke(<generated>)
18. at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
19. at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793)
20. at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
21. at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
22. at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89)
23. at skynet.boot.pandora.brave.core.PandoraTraceAspect.traceApiRequest(PandoraTraceAspect.java:96)
24. at skynet.boot.pandora.brave.core.PandoraTraceAspect.pandoraTraceStarter(PandoraTraceAspect.java:52)
25. at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
26. at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
27. at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
28. at java.lang.reflect.Method.invoke(Method.java:498)

---

_**Assistant**_



---

好的，我来分析一下您提供的日志。

日志中主要有两个关键错误信息：

1.  **CUDA 错误**:
    `CUDA error cudaErrorNoKernelImageForDevice:no kernel image is available for execution on the device`
    这个错误表明，尝试在 GPU 上执行的 CUDA 内核（kernel）与当前的 GPU 设备不兼容。通常，这意味着：
    *   **编译的 CUDA 计算能力 (Compute Capability) 不匹配**：您的应用程序或 ONNX 模型可能是为特定版本的 CUDA 计算能力编译的，而当前运行环境的 GPU 不支持该版本，或者支持的版本较低/较高。
    *   **驱动程序或 CUDA 工具包版本问题**：GPU 驱动程序版本、CUDA 工具包版本以及编译模型时使用的 CUDA 版本之间可能存在不兼容。
    *   **ONNX Runtime 问题**：ONNX Runtime 在执行模型时，依赖于正确的 CUDA 后端和相关的库。如果配置不当或版本不匹配，也可能导致此类错误。

2.  **Java 应用程序错误**:
    `com.iflytek.turing.docqa.exceptions.DocQaEngineException: TALKER.DOCQA.wrapperExec failed! engine code:15005`
    这个 Java 异常堆栈信息显示，在 `com.iflytek.turing.embedding.pandora.EmbeddingHandler` 处理嵌入（embedding）操作时，底层的 `DocQaWorker.embedding` 调用失败了。错误码 `15005` 以及 `TALKER.DOCQA.wrapperExec failed!` 的提示，很可能是由于前面提到的 CUDA 错误导致的。当 ONNX 模型无法在 GPU 上成功执行时，上层的 Java 应用自然会收到执行失败的错误。

**总结来说，根本原因很可能是 ONNX 模型在 GPU 上执行时遇到了 CUDA 兼容性问题。**

**建议的排查方向和可能的解决方案：**

1.  **检查 GPU 计算能力和编译选项**：
    *   确认您部署环境中的 GPU型号及其支持的 CUDA 计算能力。
    *   检查您的 ONNX 模型或其依赖的 CUDA 库在编译时，是针对哪个计算能力版本编译的。确保编译目标与实际 GPU 兼容。可能需要重新编译模型或相关组件。
2.  **检查 CUDA、cuDNN 和驱动版本**：
    *   确保 GPU 驱动程序、安装的 CUDA Toolkit 版本以及 cuDNN 库版本是相互兼容的，并且与 ONNX Runtime 所需的版本一致。有时候，升级或降级驱动/CUDA 版本可以解决问题。
3.  **检查 ONNX Runtime 版本和配置**：
    *   确认您使用的 ONNX Runtime 版本支持您 GPU 的 CUDA 版本。
    *   确保 ONNX Runtime 的 CUDA 执行提供程序 (CUDA Execution Provider) 已正确配置并启用。
4.  **环境变量**：
    *   检查相关的环境变量（如 `CUDA_VISIBLE_DEVICES`， `LD_LIBRARY_PATH` 等）是否设置正确，确保应用程序能够找到正确的 CUDA 库。
5.  **测试简单的 CUDA 程序**：
    *   尝试在同一环境运行一个简单的 CUDA 示例程序（如 CUDA SDK 中的 `deviceQuery`），以验证 CUDA 环境本身是否配置正确并且能够正常识别和使用 GPU。
6.  **模型问题**：
    *   虽然不太常见，但模型本身也可能存在问题，或者包含一些特定 GPU 架构不支持的操作。

这条日志 `OnnxModelProcess.hpp:115 onnx core run error` 指向了 ONNX 模型处理过程中 C++ 代码的错误位置，进一步佐证了问题出在 ONNX 模型执行层面。

您可以先从检查 CUDA 版本和 GPU 驱动开始。如果问题依旧，请提供更多关于您的运行环境（操作系统、GPU型号、CUDA版本、ONNX Runtime版本等）以及模型是如何编译和部署的信息，以便更精确地定位问题。

---

