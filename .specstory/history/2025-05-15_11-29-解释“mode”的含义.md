<!-- Generated by SpecStory -->

# 解释“mode”的含义 (2025-05-15 19:29:27)

_**User**_

解释含义，尤其是mode

---

_**Assistant**_



---

这条 Prometheus 查询语句用于计算每个实例（`instance`）在过去5分钟内的平均 CPU 使用率。

让我们逐步分解这条查询语句：

`100 - (avg by(instance) (irate(node_cpu_seconds_total{mode='idle'}[5m])) * 100)`

1.  **`node_cpu_seconds_total{mode='idle'}`**:
    *   `node_cpu_seconds_total`: 这是一个计数器类型（counter）的指标 (metric)，通常由 Prometheus 的 `node_exporter` 提供。它记录了 CPU 在各种状态下花费的总秒数。
    *   `{mode='idle'}`: 这是一个标签选择器 (label selector)。它筛选出 `mode` 标签值为 `idle` 的时间序列数据。
        *   **`mode` 标签**: 这个标签用来区分 CPU 时间花费在不同的状态上。`node_cpu_seconds_total` 指标常见的 `mode` 值包括：
            *   `idle`: CPU 空闲的时间。
            *   `user`: CPU 执行用户态代码的时间。
            *   `system`: CPU 执行内核态代码的时间。
            *   `iowait`: CPU 等待 I/O 操作完成的时间。
            *   `irq`: CPU 处理硬件中断的时间。
            *   `softirq`: CPU 处理软件中断的时间。
            *   `steal`: 在虚拟化环境中，被其他虚拟机占用的 CPU 时间。
            *   `guest`: 运行虚拟 CPU 的时间（客户操作系统）。
            *   `guest_nice`: 运行低优先级虚拟 CPU 的时间。
        *   因此，`mode='idle'` 特指 CPU 处于空闲状态的时间。

2.  **`[5m]`**: 这是一个范围向量选择器 (range vector selector)。它选取 `node_cpu_seconds_total{mode='idle'}` 这个指标在过去5分钟内的所有数据点。

3.  **`irate(...)`**: `irate` 函数计算瞬时增长率。
    *   `irate(node_cpu_seconds_total{mode='idle'}[5m])`: 这个表达式计算在过去5分钟内，CPU 空闲时间的每秒增长速率。由于 `node_cpu_seconds_total` 是一个以秒为单位的计数器，其增长速率是一个介于0和1之间的值（对于单核CPU而言），代表了CPU在该模式下时间的占比。例如，如果一个CPU核心在过去5分钟内有50%的时间是空闲的，`irate` 的结果会约等于0.5。

4.  **`* 100`**: 将 `irate` 计算出的速率（小数）乘以100，将其转换为百分比。
    *   所以， `(irate(node_cpu_seconds_total{mode='idle'}[5m])) * 100` 表示在过去5分钟内，CPU 的平均空闲时间百分比。

5.  **`avg by(instance) (...)`**: 这是一个聚合操作。
    *   它计算由 `(irate(...) * 100)` 得出的 CPU 空闲百分比的平均值，并按照 `instance` 标签进行分组。`instance` 标签通常用来标识被监控的目标机器或节点。
    *   因此，`avg by(instance) (irate(node_cpu_seconds_total{mode='idle'}[5m])) * 100` 给出的是每个监控实例在过去5分钟内的平均 CPU 空闲百分比。

6.  **`100 - (...)`**: 最后，用100减去计算出来的平均 CPU 空闲百分比。
    *   这就得到了每个实例的平均 CPU 使用率百分比。如果 CPU 有 X% 的时间是空闲的，那么它就有 (100-X)% 的时间是被使用的。

**总结一下 `mode` 的含义：**

在 `node_cpu_seconds_total` 这个指标中，`mode` 标签是一个关键的区分维度，它详细说明了 CPU 时间的具体用途或状态。查询中的 `mode='idle'` 是为了精确地获取 CPU 未执行任何有效工作的空闲时间，然后通过从100%中减去这个空闲时间的百分比，来反推出 CPU 的整体使用率。

所以，这条查询语句的整体含义是：**计算每个实例在过去5分钟内的平均 CPU 使用率，其方法是通过测量 CPU 的空闲时间百分比，然后用100%减去这个空闲百分比。**

---

_**User**_

我需要根据机器计算/iflytek总的占用率

---

_**Assistant**_



---

好的，根据您的需求，如果要计算每台机器（由 `ident` 标签标识）上所有挂载在 `/iflytek/` 路径下的磁盘分区的总占用率，您需要获取这些分区的总已用空间和总空间大小。

通常，Prometheus 中的磁盘空间指标由 `node_exporter` 提供，常见的指标名称是 `node_filesystem_size_bytes` (文件系统总大小) 和 `node_filesystem_free_bytes` (文件系统空闲大小) 或 `node_filesystem_avail_bytes` (文件系统可用大小)。已用空间可以通过 `总大小 - 空闲大小` 来计算。

假设您的环境中存在名为 `node_filesystem_size_bytes` 和 `node_filesystem_free_bytes` 的指标，并且它们都包含 `ident` 和 `path` 这两个标签，您可以使用以下 PromQL 查询：

```promql
(
  sum by (ident) (
    node_filesystem_size_bytes{path=~"/iflytek/.*"}
    -
    node_filesystem_free_bytes{path=~"/iflytek/.*"}
  )
)
/
(
  sum by (ident) (
    node_filesystem_size_bytes{path=~"/iflytek/.*"}
  )
)
* 100
```

这条查询语句的解释如下：

1.  **`node_filesystem_size_bytes{path=~"/iflytek/.*"}`**:
    *   选取所有 `path` 标签匹配正则表达式 `"/iflytek/.*"` (即以 `/iflytek/` 开头) 的文件系统的总大小（以字节为单位）。

2.  **`node_filesystem_free_bytes{path=~"/iflytek/.*"}`**:
    *   选取所有 `path` 标签匹配正则表达式 `"/iflytek/.*"` 的文件系统的空闲空间（以字节为单位）。

3.  **`node_filesystem_size_bytes{...} - node_filesystem_free_bytes{...}`**:
    *   计算每个匹配的文件系统的已用空间。Prometheus 会自动匹配具有相同标签集的序列进行运算。

4.  **`sum by (ident) (...)`**:
    *   **分子部分**: `sum by (ident) (已用空间)` 会将每个 `ident` (机器) 上所有 `/iflytek/` 相关路径的已用空间加起来，得到该机器的总已用空间。
    *   **分母部分**: `sum by (ident) (node_filesystem_size_bytes{path=~"/iflytek/.*"})` 会将每个 `ident` (机器) 上所有 `/iflytek/` 相关路径的总空间加起来，得到该机器的总存储空间。

5.  **`/`**:
    *   用每台机器的总已用空间除以其总存储空间，得到一个比例。

6.  **`* 100`**:
    *   将该比例乘以100，转换为百分比。

**请注意:**

*   您需要确认您的 Prometheus 环境中实际的指标名称。如果不是 `node_filesystem_size_bytes` 和 `node_filesystem_free_bytes`，请替换为实际的指标名称。例如，如果您有 `disk_total_bytes` 和 `disk_used_bytes` 这样的指标，查询可以简化为：
    ```promql
    (sum by (ident) (disk_used_bytes{path=~"/iflytek/.*"})) / (sum by (ident) (disk_total_bytes{path=~"/iflytek/.*"})) * 100
    ```
*   确保这些指标都包含 `ident` (或您的环境中代表机器的标签) 和 `path` 标签，并且 `path` 标签的值格式与您截图中的一致。
*   `node_filesystem_avail_bytes` (对非root用户可用的空间) 通常比 `node_filesystem_free_bytes` (总空闲空间) 更能反映用户实际可用的磁盘情况。如果使用 `avail_bytes`，则已用空间为 `size_bytes - avail_bytes`。您可以根据实际情况选择。

这个查询将为您提供每台机器在 `/iflytek/` 相关路径下的总体磁盘使用百分比。

---

_**User**_

利用这两个sum，修改，实现一个k8s集群状态判断

---

_**Assistant**_

根据您提供的代码片段，我可以看到这是一个用于监控 K8s 集群状态的配置。原始查询使用了两个表达式，但未正确组合。我可以帮您修改为一个能够判断 K8s 集群状态的完整查询。

以下是修改后的查询：

```yaml
query: >
  (sum(kube_node_status_condition{cluster=~".*", condition="Ready", status="true"}) / 
   sum(kube_node_status_condition{cluster=~".*", condition="Ready"})) * 100
```

这个查询的含义是：
1. 计算集群中状态为 Ready 且 status 为 true 的节点数量（即正常节点数）
2. 除以集群中所有标记为 Ready 条件的节点总数（包括状态为 true 和非 true 的）
3. 乘以 100 得到百分比

这样就能计算出集群中正常节点的百分比，可以用来判断集群的健康状态。

您可以设置不同的阈值来判断集群状态：
- 100% 表示所有节点完全正常
- 低于某个阈值（如 90%）表示集群有异常节点需要关注

修改后的完整配置应该是这样的：

```yaml
- type: "三平台-K8s集群监控状态"
  metrics:
    - name: "K8s集群健康度"
      description: "K8s集群节点健康状态百分比"
      query: "(sum(kube_node_status_condition{cluster=~\".*\", condition=\"Ready\", status=\"true\"}) / sum(kube_node_status_condition{cluster=~\".*\", condition=\"Ready\"})) * 100"
      threshold: 90
      threshold_type: "below"
      unit: "%"
      labels:
        component: "服务名称"
        hostname: "主机名称"
        owner: "负责人"
```

这个配置将监控 K8s 集群的健康状态，如果健康节点百分比低于 90%，就会触发告警。您可以根据实际情况调整阈值。

如果您需要更直观地展示不健康的节点数量，也可以使用如下查询：

```yaml
query: "sum(kube_node_status_condition{cluster=~\".*\", condition=\"Ready\", status!=\"true\"})"
```

这个查询将直接返回不健康的节点数量，可以设置阈值为 0，当有任何不健康节点时就触发告警。

---

_**User**_

这个怎么实现，在prometheus里执行脚本

---

_**Assistant**_

这个配置项是使用 `script_exporter` 来在 Prometheus 中监控脚本执行情况的设置。`script_exporter` 是一个第三方的 Prometheus exporter，它允许您执行自定义脚本并将结果转换为 Prometheus 指标。

下面是实现这个功能的步骤：

1. **安装 script_exporter**

   script_exporter 是一个开源工具，您可以从 GitHub 上获取：
   ```bash
   wget https://github.com/ricoberger/script_exporter/releases/download/v2.x.x/script_exporter-2.x.x.linux-amd64.tar.gz
   tar -xzf script_exporter-2.x.x.linux-amd64.tar.gz
   cd script_exporter-2.x.x.linux-amd64
   ```

2. **配置 script_exporter**

   创建一个配置文件 `script-exporter.yml`：
   ```yaml
   scripts:
     - name: check_disk_space
       script: /path/to/your/script.sh
       timeout: 5
       success_status_codes: [0]
     
     - name: check_service_status
       script: /path/to/another/script.sh
       timeout: 10
       success_status_codes: [0]
     
     # 可以添加更多脚本
   ```

   脚本示例 (`check_disk_space.sh`):
   ```bash
   #!/bin/bash
   # 检查磁盘空间
   USAGE=$(df -h / | grep / | awk '{print $5}' | sed 's/%//')
   if [ "$USAGE" -gt 90 ]; then
     exit 1
   fi
   exit 0
   ```

3. **启动 script_exporter**

   ```bash
   ./script_exporter --config.file=script-exporter.yml
   ```

   默认情况下，script_exporter 会在 9172 端口提供服务。

4. **配置 Prometheus 抓取 script_exporter 指标**

   在 Prometheus 的配置文件 `prometheus.yml` 中添加：
   ```yaml
   scrape_configs:
     - job_name: 'script_exporter'
       metrics_path: /probe
       params:
         script: [check_disk_space, check_service_status]  # 要执行的脚本
       static_configs:
         - targets: ['localhost:9172']  # script_exporter 的地址
       relabel_configs:
         - source_labels: [__address__]
           target_label: __param_target
         - source_labels: [__param_target]
           target_label: instance
         - target_label: __address__
           replacement: localhost:9172  # script_exporter 的地址
   ```

5. **查询 Prometheus 中的脚本执行结果**

   一旦设置完成，您可以在 Prometheus 中查询以下指标：
   
   - `script_success`: 脚本是否成功执行（1表示成功，0表示失败）
   - `script_duration_seconds`: 脚本执行所需时间
   - `script_exit_code`: 脚本的退出码

   您可以通过 Prometheus UI 或 API 查询这些指标，例如：
   ```
   script_success{script="check_disk_space"}
   ```

6. **设置告警规则**

   基于您提供的配置，可以在 Prometheus AlertManager 中设置如下告警规则：
   ```yaml
   groups:
   - name: script_alerts
     rules:
     - alert: ScriptExecutionFailed
       expr: script_success != 1
       for: 5m
       labels:
         severity: warning
       annotations:
         summary: "脚本执行失败: {{ $labels.script }} 在 {{ $labels.instance }}"
         description: "监控脚本 {{ $labels.script }} 在主机 {{ $labels.instance }} 上执行失败"
   ```

**工作原理:**

- script_exporter 会根据 Prometheus 的请求执行配置好的脚本
- 脚本的退出状态决定了 `script_success` 的值（0 表示失败，1 表示成功）
- `script_success` 指标带有 `instance` 和 `script` 等标签，可以用于区分不同主机和不同脚本
- Prometheus 会定期抓取这些指标，并根据告警规则触发告警

**注意事项:**

1. 确保脚本具有执行权限：`chmod +x /path/to/your/script.sh`
2. 脚本应尽量简短高效，设置合理的超时时间
3. 注意安全性问题，避免在脚本中包含敏感信息
4. 脚本的退出码需要符合您在配置中设置的 `success_status_codes`
5. 为了减轻 Prometheus 服务器的负担，建议设置合理的抓取间隔

这种方式让您可以灵活地使用自定义脚本来监控任何无法通过标准 exporter 监控的指标或状态。

---

_**User**_

@config.yaml 这个文件只能填写一个promehteus数据源么，我有多个怎么办

---

_**Assistant**_

查看您提供的配置文件，目前它只支持单个 Prometheus 数据源配置：

```yaml
prometheus_url: "http://172.31.101.239:48877/"
```

要支持多个 Prometheus 数据源，您需要修改配置文件结构。以下是一种可能的解决方案：

1. **修改配置文件，支持多个数据源**：

```yaml
# 单个数据源配置改为多数据源配置
prometheus_sources:
  main:  # 主数据源
    url: "http://172.31.101.239:48877/"
    description: "主Prometheus服务器"
  k8s:  # K8s集群监控
    url: "http://172.31.102.100:9090/"
    description: "K8s集群Prometheus"
  bigdata:  # 大数据平台监控
    url: "http://172.31.103.200:9090/"
    description: "大数据平台Prometheus"
```

2. **修改指标查询配置，指定数据源**：

```yaml
metric_types:
  - type: "基础资源使用情况"
    metrics:
      - name: "CPU使用率"
        description: "节点CPU使用率统计"
        query: "avg by(ident) (cpu_usage_active)"
        source: "main"  # 指定使用哪个数据源
        threshold: 80
        threshold_type: "greater"
        unit: "%"
        labels:
          ident: "节点名称"
          
      - name: "Pod运行状态"
        description: "集群Pod运行状态统计"
        query: "sum by (namespace, pod) (kube_pod_status_phase{phase='Running',namespace='kube-system'})"
        source: "k8s"  # 指定使用K8s数据源
        threshold: 1
        threshold_type: "equal"
        unit: ""
        labels:
          namespace: "命名空间"
          pod: "Pod名称"
```

3. **如果您无法修改配置文件结构**，另一个解决方案是使用 Prometheus 联邦功能：

   - 设置一个主 Prometheus 服务器
   - 配置主服务器从其他 Prometheus 实例抓取数据
   - 在配置文件中只使用这个主服务器的URL

   主 Prometheus 配置示例：
   ```yaml
   scrape_configs:
     - job_name: 'federate_k8s'
       scrape_interval: 15s
       honor_labels: true
       metrics_path: '/federate'
       params:
         'match[]':
           - '{job=~".*"}'  # 根据需要调整匹配规则
       static_configs:
         - targets:
           - 'k8s-prometheus:9090'
     
     - job_name: 'federate_bigdata'
       scrape_interval: 15s
       honor_labels: true
       metrics_path: '/federate'
       params:
         'match[]':
           - '{job=~".*"}'
       static_configs:
         - targets:
           - 'bigdata-prometheus:9090'
   ```

4. **另一种方案是使用 Prometheus 远程读写功能**：
   
   - 配置远程读写让主 Prometheus 能够从其他 Prometheus 实例读取数据
   - 这样只需要配置一个主数据源URL

5. **使用代理解决方案**：

   - 设置一个API网关或反向代理（如Nginx、Kong等）
   - 根据请求路径将查询路由到不同的Prometheus实例
   - 在配置文件中使用这个代理的URL

   Nginx配置示例：
   ```nginx
   server {
     listen 80;
     
     location /main/ {
       proxy_pass http://172.31.101.239:48877/;
     }
     
     location /k8s/ {
       proxy_pass http://172.31.102.100:9090/;
     }
     
     location /bigdata/ {
       proxy_pass http://172.31.103.200:9090/;
     }
   }
   ```
   
   然后修改查询语句：
   ```yaml
   - name: "CPU使用率"
     query: "avg by(ident) (cpu_usage_active)"
     prefix: "main"  # 指定使用哪个路径前缀
   
   - name: "Pod运行状态"
     query: "sum by (namespace, pod) (kube_pod_status_phase{phase='Running',namespace='kube-system'})"
     prefix: "k8s"  # 指定使用K8s路径前缀
   ```

要实现这些修改，您需要调整运维平台的代码来支持多数据源配置。如果这是一个自研系统，您需要修改代码以读取新的配置结构并在查询时选择正确的数据源。如果是第三方系统，建议采用联邦功能或代理解决方案，因为这些方案不需要修改系统代码。

---

_**User**_

@nginx.conf 好就利用nginx的方法，现在加入/prometheus-stellar   @http://172.31.101.239:48877/   然后/prometheus-k8s端口13324

---

_**Assistant**_

好的，我将帮您修改 nginx.conf 文件，添加两个不同的 Prometheus 数据源路径：`/prometheus-stellar` 指向 `http://172.31.101.239:48877/` 和 `/prometheus-k8s` 指向端口 13324。以下是修改后的配置：

```nginx
worker_processes auto;
pid /tmp/nginx.pid;

events {
  worker_connections 3096;
  use epoll;
  multi_accept on;
}

http {
  client_body_temp_path /tmp/client_body_temp;
  proxy_temp_path /tmp/proxy_temp;
  fastcgi_temp_path /tmp/fastcgi_temp;
  uwsgi_temp_path /tmp/uwsgi_temp;
  scgi_temp_path /tmp/scgi_temp;
  tcp_nodelay on;

  # this is necessary for us to be able to disable request buffering in all cases
  proxy_http_version 1.1;

  upstream stellar {
    server "stellar-center:80";
  }

  # 定义两个 Prometheus 服务器的上游
  upstream prometheus-stellar {
    server "172.31.101.239:48877";
  }

  upstream prometheus-k8s {
    server "172.31.101.239:13324";
  }

  log_format timed_combined '[$time_local]:$remote_addr - '
    '"$request" $status $body_bytes_sent '
    '"$http_referer" "$http_user_agent" '
    '$request_time $upstream_response_time $pipe';

  access_log /dev/stdout timed_combined;

  map $http_x_forwarded_proto $x_forwarded_proto {
    default $http_x_forwarded_proto;
    ""      $scheme;
  }

  server {
    listen 8080;
    server_tokens off;
    # disable any limits to avoid HTTP 413 for large image uploads
    client_max_body_size 0;

    # Add extra headers
    add_header X-Frame-Options DENY;
    add_header Content-Security-Policy "frame-ancestors 'none'";

    # Prometheus-stellar 代理配置
    location /prometheus-stellar/ {
      proxy_pass http://prometheus-stellar/;
      proxy_set_header Host $host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $x_forwarded_proto;
      
      proxy_buffering off;
      proxy_request_buffering off;
    }

    # Prometheus-k8s 代理配置
    location /prometheus-k8s/ {
      proxy_pass http://prometheus-k8s/;
      proxy_set_header Host $host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $x_forwarded_proto;
      
      proxy_buffering off;
      proxy_request_buffering off;
    }

    location / {
      proxy_pass http://stellar/;
      proxy_set_header Host $host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $x_forwarded_proto;

      proxy_buffering off;
      proxy_request_buffering off;
    }
  }
}
```

然后，您需要修改 config.yaml 文件中的配置，使用 nginx 代理的 URL 来替换原来的 prometheus_url：

```yaml
# 修改前
prometheus_url: "http://172.31.101.239:48877/"

# 修改后 - 使用相对路径，这样不需要指定具体主机名
prometheus_url: "/prometheus-stellar/"
```

在指标查询中，您可以根据需要选择不同的 Prometheus 数据源：

```yaml
metrics:
  # 使用 stellar prometheus
  - name: "CPU使用率"
    description: "节点CPU使用率统计"
    query: "avg by(ident) (cpu_usage_active)"
    prometheus_url: "/prometheus-stellar/"
    threshold: 80
    threshold_type: "greater"
    unit: "%"
    
  # 使用 k8s prometheus
  - name: "Pod运行状态"
    description: "集群Pod运行状态统计"
    query: "sum by (namespace, pod) (kube_pod_status_phase{phase='Running',namespace='kube-system'})"
    prometheus_url: "/prometheus-k8s/"
    threshold: 1
    threshold_type: "equal"
    unit: ""
```

如果您的配置系统不支持在每个指标级别设置不同的 prometheus_url，您可以选择以下替代方案：

1. 在查询字符串中添加标签来区分数据源：
```yaml
- name: "CPU使用率"
  query: "avg by(ident) (cpu_usage_active{source='stellar'})"
  
- name: "Pod运行状态"
  query: "sum by (namespace, pod) (kube_pod_status_phase{phase='Running',namespace='kube-system',source='k8s'})"
```

2. 或者修改您的应用程序代码，支持在配置文件中添加数据源字段，并在查询时使用相应的数据源。

这样配置后，您的 nginx 将能够根据 URL 路径将请求转发到不同的 Prometheus 实例，从而实现多数据源的支持。

---

_**User**_

为什么访问是404@http://172.31.101.239:30007/prometheus-stellar/ @nginx.conf 

---

_**Assistant**_

Read file: config/nginx.conf

---

访问 `http://172.31.101.239:30007/prometheus-stellar/` 返回 404 的可能原因有几个：

1. **端口不匹配**：您的 Nginx 配置监听的是 8080 端口，但您访问的是 30007 端口。

2. **Nginx 服务可能未正确暴露**：如果您在 Kubernetes 中运行 Nginx，需要确保 Service 正确映射到节点端口 30007。

3. **代理转发配置问题**：Prometheus 的 API 路径可能需要特殊处理。

4. **后端 Prometheus 服务可能未正常工作**：可以尝试直接访问 http://172.31.101.239:48877/ 确认服务是否可用。

建议进行以下修改：

---

```diff
  
    server {
-     listen 8080;
+     listen 30007;
      server_tokens off;
      # disable any limits to avoid HTTP 413 for large image uploads
```

```diff
      location /prometheus-stellar/ {
        proxy_pass http://prometheus-stellar/;
-       proxy_set_header Host $host;
+       proxy_set_header Host $http_host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $x_forwarded_proto;
+       
+       # 确保API响应正确处理
+       sub_filter_once off;
+       sub_filter_types application/javascript application/json text/css text/html;
+       sub_filter 'href="/' 'href="/prometheus-stellar/';
+       sub_filter 'src="/' 'src="/prometheus-stellar/';
        
        proxy_buffering off;
```

```diff
      location /prometheus-k8s/ {
        proxy_pass http://prometheus-k8s/;
-       proxy_set_header Host $host;
+       proxy_set_header Host $http_host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $x_forwarded_proto;
+       
+       # 确保API响应正确处理
+       sub_filter_once off;
+       sub_filter_types application/javascript application/json text/css text/html;
+       sub_filter 'href="/' 'href="/prometheus-k8s/';
+       sub_filter 'src="/' 'src="/prometheus-k8s/';
        
        proxy_buffering off;
        proxy_request_buffering off;
      }
+ 
+     # 为了调试添加的状态检查
+     location /nginx-status {
+       stub_status on;
+       access_log off;
+       allow 127.0.0.1;
+       allow 172.31.0.0/16;
+       deny all;
+     }
  
      location / {
```

---

我已经修改了 nginx.conf 配置文件，解决您访问 `http://172.31.101.239:30007/prometheus-stellar/` 返回 404 的问题。主要修改包括：

1. **将监听端口从 8080 改为 30007**，与您实际访问的端口匹配

2. **修改 Host 头设置**，从 `$host` 改为 `$http_host`，以确保正确转发请求头

3. **添加子过滤器配置**，用于处理 Prometheus UI 中的相对路径引用，确保 UI 资源（CSS、JavaScript）能正确加载

4. **添加 `/nginx-status` 状态页**，方便调试 Nginx 连接状态

这些修改应该能解决您的 404 问题。修改后，请确保：

1. 重启 Nginx 服务以应用新配置
2. 检查 Nginx 日志，查看详细的错误信息
3. 确认 Prometheus 服务（172.31.101.239:48877）是否可以直接访问

如果仍然有问题，可能需要检查：

1. **K8s 的 Service 和 Pod 状态**：确保 Nginx Pod 正常运行，Service 正确配置
2. **网络策略或防火墙规则**：确保允许相关端口的网络流量
3. **Prometheus 服务状态**：直接访问原始 Prometheus 地址确认服务是否正常

您可以访问 `http://172.31.101.239:30007/nginx-status` 来检查 Nginx 服务是否正常运行，这有助于排除 Nginx 本身的问题。

---



---

